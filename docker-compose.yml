version: "3.9"

services:

  llm-ids:
    build:
      context: .
      dockerfile: Dockerfile

    container_name: llm-ids

    ports:
      - "8000:8000"

    environment:
      IDS_DB_PATH: /data/ids.db
      IDS_ALERT_THRESHOLD: 80

      # talk to local Windows Ollama
      OLLAMA_BASE_URL: http://host.docker.internal:11434
      OLLAMA_MODEL: llama3.2:3b-instruct-q4_K_M

      LLM_EXECUTOR_TIMEOUT_S: 60

    volumes:
      - ./data:/data

    restart: unless-stopped
